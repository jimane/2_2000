```python
import numpy as np
import matplotlib.pyplot as plt
import os
import cv2 as cv
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import shape,math 
from tensorflow.keras import Input,layers,Model
from tensorflow.keras.losses import mse,binary_crossentropy
from tensorflow.keras.utils import plot_model
```

## 1. 데이터 불러오기


```python
def DataLoad(src):
    temp = []
    files = os.listdir(src)
    for i in range(len(os.listdir(src))):
        if files[i][-4:] == '.jpg':
            temp.append(files[i])
    print(len(temp))
    return temp

src = 'C:/Users/105/Desktop/datasets/cats_and_dogs/cats/'
filenames = DataLoad(src)
```

    2000
    


```python
# 이미지 읽기 및 출력
def img_plot(img):
    plt.imshow(img)
    plt.show()
    
def img_read(src,file):
    img = cv.imread(src+file, cv.IMREAD_GRAYSCALE)
    img = cv.resize(img, (128,128))
    return img

X,Y = [] , []
count = 0

# 경로와 파일명을 입력으로 넣어서 확인하고
# 데이터를 255로 나누어서 0~1 사이로 정규화 하여 X 리스트에 넣습니다.
for name in filenames :
    X.append(img_read(src,name)/255.)
    Y.append(float(name[4:5]))

#print(Y)
# array로 데이터 변환
X = np.asarray(X)
Y = np.asarray(Y)

# X dataset 일부 확인
for i in range(10):
    img = X[i]
    img_plot(img)
print('X_list shape:', np.shape(X), 'Y_list shape', np.shape(Y))
```


    
![png](output_3_0.png)
    



    
![png](output_3_1.png)
    



    
![png](output_3_2.png)
    



    
![png](output_3_3.png)
    



    
![png](output_3_4.png)
    



    
![png](output_3_5.png)
    



    
![png](output_3_6.png)
    



    
![png](output_3_7.png)
    



    
![png](output_3_8.png)
    



    
![png](output_3_9.png)
    


    X_list shape: (2000, 128, 128) Y_list shape (2000,)
    


```python
# Train set, Test set 으로 나누기
x_train , x_test , y_train , y_test = train_test_split(X,Y, test_size=0.2, random_state=5, shuffle=True)
x_train = np.array(x_train)
x_test = np.array(x_test)

# (image,image) 이미지를 (image * image) 크기의 벡터로 만듭니다.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:]))).astype('float32')
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:]))).astype('float32')

print("Datasets_train_shape:{} Datasets_test_shape:{}".format(np.shape(x_train),np.shape(x_test)))
```

    Datasets_train_shape:(1600, 16384) Datasets_test_shape:(400, 16384)
    

## 2. VAE 모델만들기


```python
# 네트워크 파라메타
input_shape = np.shape(x_train[0])[0]
original_dim = input_shape
_1st_dim = 4096
_2nd_dim = 2048
_3rd_dim = 1024
_4th_dim = 512
_5th_dim = 256
latent_dim = 2
```

## 3. Encoder 생성


```python
def encoder():
    # 인코더의 입력층을 생성
    inputs = Input(shape=(input_shape,), name='input_shape')
    
    # 인코더의 hidden층을 생성, 500개의 유닛을 사용
    encoder_hidden = layers.Dense(_1st_dim, activation = 'relu', name='encoder_hidden1')(inputs)
    encoder_hidden = layers.Dense(_2nd_dim, activation = 'relu', name='encoder_hidden2')(encoder_hidden)
    encoder_hidden = layers.Dense(_3rd_dim, activation = 'relu', name='encoder_hidden3')(encoder_hidden)
    encoder_hidden = layers.Dense(_4th_dim, activation = 'relu', name='encoder_hidden4')(encoder_hidden)
    encoder_hidden = layers.Dense(_5th_dim, activation = 'relu', name='encoder_hidden5')(encoder_hidden)
    
    # 평균(mean)과 표준편차(sigma)층을 정의
    # 이떄 sigma 대신 log variance를 사용. 신경망의 출력은 음수를 가질 수 있지만, sigma는 항상 양수여야함
    # 각각 2개의 유닛을 사용.
    z_mean = layers.Dense(latent_dim, name='z_mean')(encoder_hidden)
    z_log_var = layers.Dense(latent_dim, name='z_log_var')(encoder_hidden)
    
    # 평균과 표준편차를 매핑하여 Z_sampling층 생성
    
    # Z 샘플링 함수 생성
    def sampling(args):
        z_mean, z_log_var = args
        batch = shape(z_mean)[0]
        dim = shape(z_mean)[1]
        
        # 보편적으로 , 정규분포의 평균은 0, 표준편차는 1
        # Reparameterization Trick사용을 위해 Gussian(=normal)분포에서 랜덤변수(sample) 입실론 추출
        epsilon = tf.compat.v2.random.normal(shape=(batch,dim))
        return z_mean + tf.math.exp(0.5 * z_log_var) * epsilon
    
    # layers.Lambda API 래핑에 사용할 함수와, 유닛수(n, )를 지정
    z_sampling = layers.Lambda(sampling, (latent_dim), name='z_sample')([z_mean, z_log_var])
    
    # 하나의 입력과 다중출력을 포함하는 encoder 모델 생성
    return Model(inputs, [z_mean, z_log_var,z_sampling], name='encoder')

encoder = encoder()

encoder.summary()
plot_model(encoder, to_file='vae_mip_encoder.png', show_shapes=True)
```

    Model: "encoder"
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_shape (InputLayer)        [(None, 16384)]      0                                            
    __________________________________________________________________________________________________
    encoder_hidden1 (Dense)         (None, 4096)         67112960    input_shape[0][0]                
    __________________________________________________________________________________________________
    encoder_hidden2 (Dense)         (None, 2048)         8390656     encoder_hidden1[0][0]            
    __________________________________________________________________________________________________
    encoder_hidden3 (Dense)         (None, 1024)         2098176     encoder_hidden2[0][0]            
    __________________________________________________________________________________________________
    encoder_hidden4 (Dense)         (None, 512)          524800      encoder_hidden3[0][0]            
    __________________________________________________________________________________________________
    encoder_hidden5 (Dense)         (None, 256)          131328      encoder_hidden4[0][0]            
    __________________________________________________________________________________________________
    z_mean (Dense)                  (None, 2)            514         encoder_hidden5[0][0]            
    __________________________________________________________________________________________________
    z_log_var (Dense)               (None, 2)            514         encoder_hidden5[0][0]            
    __________________________________________________________________________________________________
    z_sample (Lambda)               (None, 2)            0           z_mean[0][0]                     
                                                                     z_log_var[0][0]                  
    ==================================================================================================
    Total params: 78,258,948
    Trainable params: 78,258,948
    Non-trainable params: 0
    __________________________________________________________________________________________________
    




    
![png](output_8_1.png)
    



## 4. Decoder 생성


```python
def decoder():
    
    # 디코더의 입력층을 생성. Decoder의 입력은 latent
    input_z = Input(shape=(latent_dim,), name='input_z')
    
    # 디코더의 hidden층을 생성. 인코더와 동일하게 500개의 유닛을 사용
    decoder_hidden = layers.Dense(_5th_dim, activation='relu', name='decoder_hidden1')(input_z)
    decoder_hidden = layers.Dense(_4th_dim, activation='relu', name='decoder_hidden2')(decoder_hidden)
    decoder_hidden = layers.Dense(_3rd_dim, activation='relu', name='decoder_hidden3')(decoder_hidden)
    decoder_hidden = layers.Dense(_2nd_dim, activation='relu', name='decoder_hidden4')(decoder_hidden)
    decoder_hidden = layers.Dense(_1st_dim, activation='relu', name='decoder_hidden5')(decoder_hidden)

    # 디코더의 출력층은 인코더 입력벡터 수만큼 유닛을 사용
    outputs = layers.Dense(original_dim, activation = 'sigmoid', name='output')(decoder_hidden)
    
    return Model(input_z, outputs, name='decoder')

decoder = decoder()

decoder.summary()
plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)
```

    Model: "decoder"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_z (InputLayer)         [(None, 2)]               0         
    _________________________________________________________________
    decoder_hidden1 (Dense)      (None, 256)               768       
    _________________________________________________________________
    decoder_hidden2 (Dense)      (None, 512)               131584    
    _________________________________________________________________
    decoder_hidden3 (Dense)      (None, 1024)              525312    
    _________________________________________________________________
    decoder_hidden4 (Dense)      (None, 2048)              2099200   
    _________________________________________________________________
    decoder_hidden5 (Dense)      (None, 4096)              8392704   
    _________________________________________________________________
    output (Dense)               (None, 16384)             67125248  
    =================================================================
    Total params: 78,274,816
    Trainable params: 78,274,816
    Non-trainable params: 0
    _________________________________________________________________
    




    
![png](output_10_1.png)
    



## 5. VAE모델 생성


```python
def vae():
    # vae는 입력으로 이미지가 들어와 encoder를 통해 z_sampling 되어 decoder로 출력
    inputs = Input(shape=(input_shape), name='input_shape')
    outputs = decoder(encoder(inputs)[2]) #[0]:z_mean, [1]:z_olg_var , [2]:z_sampling
    
    return Model(inputs, outputs, name='vae_mlp')

# VAE 모델 정의
model = vae()
model.summary()
plot_model(model, to_file='vae_mip.png', show_shapes=True)
```

    Model: "vae_mlp"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_shape (InputLayer)     [(None, 16384)]           0         
    _________________________________________________________________
    encoder (Functional)         [(None, 2), (None, 2), (N 78258948  
    _________________________________________________________________
    decoder (Functional)         (None, 16384)             78274816  
    =================================================================
    Total params: 156,533,764
    Trainable params: 156,533,764
    Non-trainable params: 0
    _________________________________________________________________
    




    
![png](output_12_1.png)
    




```python
# 하이퍼 파라메타 설정
num_epochs = 2000
batch_size = 20
learning_rate = 1e-4
```


```python
# 모델 학습 loss, optimizer 정의
adam = tf.keras.optimizers.Adam(learning_rate = learning_rate)
def vae_loss(x,recon_x):
    # (1)Reconstruct loss (Marginal_likelihood) : Cross-entropy
    z_mean, z_log_var, z_sampling = encoder(x)
    recon_x = decoder(z_sampling)
    reconstruction_loss = binary_crossentropy(x, recon_x)
    # reconstruction_loss = mse(inputs, outputs)
    reconstruction_loss *= original_dim
    # (2) KL divergence(Latent_loss)
    kl_loss = 0.5 * tf.reduce_sum(tf.square(z_mean)+tf.exp(z_log_var)-z_log_var -1, 1)
    return tf.reduce_mean(reconstruction_loss + kl_loss) #ELBO(=VAE_loss)

model.compile(optimizer=adam, loss=vae_loss)
```


```python
# 모델 학습
hist = model.fit(x_train, x_train, epochs=num_epochs, batch_size=batch_size)
# 학습된 VAE 모델 저장
model.save_weights('vae_bracket.h5')
```

   
    Epoch 2000/2000
    80/80 [==============================] - 2s 31ms/step - loss: 10254.4404
    

## 6. 원본이미지와 복원이미지 비교


```python
recon_x_test = model.predict(x_test)

n = 10 # how many digits we will display
plt.figure(figsize=(15,4))
for i in range(10):
    # display original
    ax = plt.subplot(2, n , i + 1)
    plt.imshow(x_test[i].reshape(128 ,128), vmin=0, vmax=1, cmap="gray")
    plt.title("Input"+str(i))
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    # plt.colorbar()
    
    # display reconstruction
    ax = plt.subplot(2, n , i + 1 + n)
    plt.imshow(recon_x_test[i].reshape(128, 128), vmin=0, vmax=1, cmap="gray")
    plt.title("Recon"+str(i))
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    # plt.colorbar()

plt.show()
```


    
![png](output_17_0.png)
    


## 7. 2D공간에 잠재된 데이터 출력


```python
 #학습모델이 생성한 Manifold를 plot하는 함수 정의
def plot_results(models,
                 data,
                 batch_size=batch_size,
                 model_name="vae_mnist"):
    encoder, decoder = models
    x_test, y_test = data
    filename = "digits_over_latent.png"
    # display a 30x30 2D manifold of digitsa
    n = 15
    digit_size = 128
    figure = np.zeros((digit_size * n, digit_size * n))
    # linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space
    grid_x = np.linspace(-2, 2, n)
    grid_y = np.linspace(-2, 2, n)[::-1]

    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = decoder.predict(z_sample)
            digit = x_decoded[0].reshape(digit_size, digit_size)
            figure[i * digit_size: (i + 1) * digit_size,
                   j * digit_size: (j + 1) * digit_size ] = digit

    plt.figure(figsize=(10, 10))
    start_range = digit_size // 2
    end_range = (n - 1) * digit_size + start_range + 1
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.imshow(figure, cmap='Greys_r')
    plt.savefig(filename)
    plt.show()
    
plot_results(models = (encoder, decoder),
                 data = (x_test, y_test),
                 batch_size=batch_size,
                 model_name="vae_mlp")## 7. 2D공간에 잠재된 데이터 출력
```


    
![png](output_19_0.png)
    



```python
def tsne_plot_results(models, data, batch_size=128, model_name='vae_mnist'):
    encoder , decoder = models
    x_test , y_test = data
    os.makedirs(model_name, exist_ok = True)
    
    #filename = os.path.join(model_name, "vae_mean.png")
    filename = "vae_mean.png"
    # display a 2D plot of the digit classes in the latent space
    z_mean, _, _ = encoder.predict(x_test, batch_size=batch_size)
    plt.figure(figsize=(10, 10))
    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)
    plt.colorbar()
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.savefig(filename)
    plt.show()

tsne_plot_results(models = (encoder, decoder),
                 data = (x_test, y_test),
                 batch_size=batch_size,
                 model_name="vae_mlp")
```


    
![png](output_20_0.png)
    


## 8. 데이터 간 Interpolation


```python
def linear_interpolation(x_from, x_to, steps=10):
    n = steps + 1
    t_from = x_from
    t_to = x_to
    
    diff = t_to - t_from
    inter = np.zeros((n, t_from.shape[0]))
    
    for i in range(n):
        inter[i] = t_from + i / steps * diff
        
    return decoder.predict(inter)
```


```python
target_a = np.array([1,1]) # 타겟 시작 좌표
target_b = np.array([10,10]) # 타겟 끝 좌표
z_decoder_imgs = linear_interpolation(target_a, target_b, 10)
```


```python
N = 1
M = 10
img_size = 128
fig = plt.figure(figsize=(10,10))
plt.subplots_adjust(top=1, bottom=0, hspace=0, wspace=0.05)
for i in range(N):
    for j in range(M):
        k = i * M + j
        ax = fig.add_subplot(N, M, k+1)
        ax.imshow(np.reshape(z_decoder_imgs[k], (img_size, img_size)), cmap=plt.cm.gist_gray)
        ax.grid(False)
        ax.xaxis.set_ticks([])
        ax.yaxis.set_ticks([])
plt.tight_layout()
```


    
![png](output_24_0.png)
    

